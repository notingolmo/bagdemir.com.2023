---
layout: post
title: "Virtual Threads"
description: "Consistent Hash Ring is a widely used technique in the process of distributing and load balancing data or operational workload across multiple system components with high fault tolerance."
date: 2023-11-16 08:41:50
author: Erhan Bagdemir
comments: true
keywords: "Programming, Java, Virtual Threads, Coroutines"
category: Programming
image:  '/images/21.jpg'
tags:
- Programming
- Java
---

In 2018, I had the privilege to follow a talk by Alan Bateman at Devoxx. It was about Fibers in Java, which we are familiar with from other programming languages with different names like coroutines. Though, there are slight differences between coroutines and fibers. Time passed, and Project Loom dropped the name "Fibers" and did a superb job naming them virtual threads because it describes how the Java version of collaborative threads is implemented: Just like regular threads but virtual ones. Otherwise, it could confuse the community and induce further discussions among terminology and jargon fanatics. But, putting all these aside, the main idea behind coroutines and virtual threads is to eliminate the cost of context switches between the operating system threads by implementing a lightweight concurrency mechanism at the application layer. It is especially essential for applications like web services, which must handle multiple client requests and make outgoing requests like database calls and other dependent services, i.e., IO-bound applications where the threads often need to be parked. Before we start, let's look at what is wrong with the operating system threads.

Nothing. However, operating system threads are considered expensive compared to their lightweight counterparts because their stacks will be loaded and unloaded constantly as the schedular preempts another one by interrupting the currently executing thread. The scheduler in the operating system may force it to stop according to its preemptive multitasking and time-slicing heuristics. In other words, it is all about the scheduler's decision when a thread may occupy hardware resources. Besides that, the operating system threads run in kernel space and require full privileges on system resources. This constitutes further overhead if the program often starts and stops threads instead of pooling them.

JVM threads are so-called platform threads that rest on operating system threads and have a one-to-one relationship between them. It means that whenever we create a new thread in our Java application, it will be backed by an operating system thread. Therefore, they are as expensive as operating system threads. Their stack size is fixed but can be configured before the application bootstraps, though it can't grow later. So, it is essential to determine a good ballpark number for the right stack size to satisfy threads' memory needs, keeping the memory small enough so that the overhead can be lowered during context switches. Allocating fixed-size memory space for every thread has its upper limit by the system's capacity. 

It also raises the limit of how many threads you start on the machine, while platform threads with high resource consumption are bound to hardware capacity.  

**How do Virtual Threads in JDK 21 make our programs more efficient?**

First, virtual threads, as their name state, simulate a thread virtually while mimicking them at the application layer. Therefore, they are executed in user space rather than the kernel, which saves the overhead caused by the operating system's resource allocation and checking privileges. Their stack size is dynamically resizable because the memory occupied by a virtual thread resides in the heap. It means the threads may consume no memory initially but can obtain new memory space if needed. However, the most significant benefit of using virtual threads is their multitasking implementation strategy, which is collaborative multitasking in contrast to platform threads, which employ preemptive multitasking and utilize a scheduler. So, virtual threads, as their coroutine siblings, can yield their execution for another thread at any time. Regardless, they will be executed by platform threads in the end. But, whenever the execution needs to wait for an IO operation, a virtual thread yields its execution for another one. It will consequently be detached from its carrier platform thread so that the underlying heavyweight thread can be scheduled for another virtual thread task. 

Virtual threads are a good fit for the one-thread-per-task use case. They are cheap to create, and pooling them at all is unnecessary.  If you are starting a greenfield project, don't think of using any thread pool with virtual threads. Create a new virtual thread whenever you need to start a parallelized task. 

**How to use Virtual Threads in existing applications?**

Switching from Platform to Virtual Threads should be manageable if you have already updated your project dependencies for the newest JDK release. You may face some challenges with the libraries that instrument your code, but other than that, the upgrade must be straightforward. The Thread interface remained the same so you can use the same thread instances in your application code. The requirement for pooling threads has vanished, as pooling cheap virtual threads doesn't make sense at all. Therefore, you should offload the work from thread pools to virtual threads by refactoring your code. A caveat of creating virtual threads might be the thread locals, which will still work, but due to the high scalability of virtual threads, the application may exhaust the memory. So, if you want to drop that risk, it is time to stop using thread locals, as they are never really welcomed to the applications. 

To leverage the full power of virtual threads, you should also refactor the synchronized blocks, as they would pin the virtual threads to their carrier and block the platform threads because of the "synchronized" semantics. Otherwise, another platform thread might pick up the virtual thread once it is ready to run and execute it, which violates the contract. Synchronized blocks may affect the scalability of virtual ones if the virtual thread is stuck blocked in the critical section, so you should consider replacing them, e.g., with Reentrant Locks. 

**Conclusion**

As you may have noticed, Project Loom has been going on for quite a long time. As set out in late 2017, the main challenge highlighted was implementing this new concurrency concept behind existing APIs, making it transparent for the application code. Say, if a virtual thread steps into a synchronized block and needs to wait for IO, can the carrier platform thread be detached even though it still holds the lock, and no other thread may enter the critical section again? Such design decisions may change the application's behavior and even cause deadlocks, starving threads, and breaking the thread's isolation guarantees in the execution environment. Therefore, such changes in JVM are challenging and must be carefully designed and implemented, which certainly requires much time.