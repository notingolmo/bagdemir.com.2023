---
layout: post
title: "Virtual Threads"
description: "Consistent Hash Ring is a widely used technique in the process of distributing and load balancing data or operational workload across multiple system components with high fault tolerance."
date: 2023-11-16 08:41:50
author: Erhan Bagdemir
comments: true
keywords: "Programming, Java, Virtual Threads, Coroutines"
category: Programming
image:  '/images/21.jpg'
tags:
- Programming
- Java
---

In 2018, I had the privilege to follow a talk by Alan Bateman at Devoxx. It was about Fibers in Java, which we are familiar with from other programming languages with different names like coroutines. There are slight differences between coroutines and fibers, yet this is a topic for another time. Time passed, and Project Loom dropped the name "Fibers" and did a superb job naming them virtual threads because it describes how the Java version of collaborative threads is implemented: Just like regular threads but virtual ones. Otherwise, it could confuse the community and induce further discussions among terminology and jargon fanatics. But, putting all these aside, the main idea behind coroutines and virtual threads is to eliminate the cost of context switches between the operating system threads by implementing a lightweight concurrency mechanism at the application layer. It is especially essential for applications like web services, which must handle multiple client requests and make outgoing requests like database calls and other dependent services, i.e., IO-bound applications where the threads often need to be parked. Before we start, let's look at what is wrong with the operating system threads.

Nothing. However, operating system threads are considered expensive compared to their lightweight counterparts because their stacks will be loaded and unloaded constantly as the schedular preempts another one by interrupting the currently executing thread. The scheduler in the operating system may force it to stop according to its preemptive multitasking and time-slicing heuristics. In other words, it is all about the scheduler's decision when a thread may occupy hardware resources. Besides that, the operating system threads run in kernel space and require full privileges on system resources. This constitutes further overhead if the program often starts and stops threads instead of pooling them. 

JVM threads are so-called platform threads that rest on operating system threads and have a one-to-one relationship between them. It means that whenever we create a new thread in our Java application, it will be backed by an operating system thread. Therefore, they are as expensive as operating system threads. Their stack size is fixed but can be configured before the application bootstraps, though it can't grow later. So, it is essential to determine a good ballpark number for the right stack size to satisfy threads' memory needs, keeping the memory small enough so that the overhead can be lowered during context switches. Allocating fixed-size memory space for every thread has its upper limit by the system's capacity. 

**How do Virtual Threads in JDK 21 make our programs more efficient?**

Switching from Platform to Virtual Threads should be manageable if you have already updated your project dependencies for the newest JDK release. You may face some challenges with the libraries that instrument your code, but other than that, the upgrade must be straightforward. The Thread interface remained the same so you can use the same thread instances in your application code. The requirement for pooling threads has vanished, as pooling cheap virtual threads doesn't make sense at all. Therefore, you should offload the work from thread pools to virtual threads by refactoring your code. A caveat of creating virtual threads might be the thread locals, which will still work, but due to the high scalability of virtual threads, the application may exhaust the memory. So, if you want to drop that risk, it is time to stop using thread locals, as they are never really welcomed to the applications. 

To leverage the full power of virtual threads, you should refactor the synchronized blocks, as they would pin the virtual threads to their carrier and block the platform threads because of the "synchronized" semantics. Otherwise, another platform thread might pick up the virtual thread once it is ready to run and execute it, which violates the contract. Synchronized blocks may affect the scalability of virtual ones if the virtual thread is stuck blocked in the critical section, so you should consider replacing them, e.g., with Reentrant Locks. 

**How to use Virtual Threads in existing applications?**

Switching from Platform to Virtual Threads should be manageable if you have already updated your project dependencies for the newest JDK release. You may face some challenges with the libraries that instrument your code, but other than that, the upgrade must be straightforward. The Thread interface remained the same so you can use the same thread instances in your application code. The requirement for pooling threads has vanished, as pooling cheap virtual threads doesn't make sense at all. Therefore, you should offload the work from thread pools to virtual threads by refactoring your code. A caveat of creating virtual threads might be the thread locals, which will still work, but due to the high scalability of virtual threads, the application may exhaust the memory. So, if you want to drop that risk, it is time to stop using thread locals, as they are never really welcomed to the applications. 

To leverage the full power of virtual threads, you should refactor the synchronized blocks, as synchronization would pin the virtual threads to their carrier and block the platform threads because of the "synchronized" semantics. If the platform thread attached to the virtual thread is unmounted, another platform thread might pick up the same virtual thread in the same synchronized block once it is ready to run, which violates the synchronization contract. Therefore, synchronized blocks may affect the scalability of virtual threads if they are blocked in the critical section for a long time, so you should consider replacing them, e.g., with Reentrant Locks in your code. 

Virtual threads simplify your application code since they drop the need for thread pools. Consider the parameters, what makes up a thread pool, core thread size, max size, necessity of queues, queue size, etc. All these parameters must be configured and fine-tuned according to the load on the system. With virtual threads, threadpools become obsolete. 

**Conclusion**

As you may have noticed, Project Loom has been going on for quite a long time. As set out in late 2017, the main challenge highlighted was implementing this new concurrency concept behind existing APIs, making it transparent for the application code. Say, if a virtual thread steps into a synchronized block and needs to wait for IO, can the carrier platform thread be detached even though it still holds the lock, and no other thread may enter the critical section again? Such design decisions may change the application's behavior and even cause deadlocks, starving threads, and breaking the thread's isolation guarantees in the execution environment. Therefore, such changes in JVM are challenging and must be carefully designed and implemented, which certainly requires much time.