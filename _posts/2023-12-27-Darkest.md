---
layout: post
title: "Dark Launching and Shadow Testing"
description: "'Dark Launching' refers to feature enablement in production behind the scenes, like 'Shadow Testing', which is the testing process of new application features in the background without making them generally available."
date: 2023-12-27 08:41:50
author: Erhan Bagdemir
comments: true
keywords: "Testing, Dark Launching, Shadow Testing, Release"
category: Testing
image:  '/images/21.jpg'
tags:
- Testing
- Dark Launching
- Shadow Testing
---

'Dark Launching' refers to feature enablement in production behind the scenes, like 'Shadow Testing', which is the testing process of new application features in the background without making them generally available. It aims to activate new software features before the GA without interrupting the operations and being transparent to customers. During the testing phase, you are to monitor, for example, whether the new integration works seamlessly with existing components under realistic data and load. 'Dark Launching' and 'Shadow Testing' are indeed very similar in practice and differ only in their intended purpose — and occasionally, they are used interchangeably. 

The main goal in 'Dark Launching' is to observe the behavior of the new application features under the realistic workload in the production environment. Clients are mostly unaware of the test running in the background. 'Shadow Testing', very like 'Dark Launching', is usually run on production systems against real customer requests. Customer requests are processed by the existing software components during Shadow Testing, while triggering the new components at the same time. The response from the new component is often not returned to the customer, and it is to simulate the integration of the new feature with the rest of the application. In case of an error, the output is logged out in a way that the engineering team can investigate, and the response from the existing integration is returned to the customer.

'Shadow Testing' can be thought of as an integration test with real data without the customer noticing. You may think why integration tests don't suffice to test the new software components. Integration tests are run with test users and synthetic data, which try to mimic the production data. However, synthetic data may not provide the entropy of data created by customers in production systems. This inevitably causes gaps in test coverage. Therefore, integration tests may not capture all errors that may occur in production operations, therefore 'Shadow Testing' becomes a valid option before enabling the new integration. In the next section, we will take a look at a new library, I am currently working on, which helps roll out complicated releases without making you walk a tightrope. 

## The “Darkest” may help

**Darkest** is a shadow testing and dark launching library developed for Java web services. As new service integrations always come and go, shadow testing enables development teams to carry out endpoint switches of service dependencies in a graceful way by calling both endpoints, say, A and B, and comparing their API responses. You can simply add the following maven dependency to your project to get started: 

```xml
    <dependency>
      <groupId>net.reevik</groupId>
      <artifactId>darkest</artifactId>
      <version>0.1.0</version>
    </dependency>
```

### Usage

You can consider the following code snippet how the routing configuration and router instance are created: 

```java
    RoutingConfiguration<String> routingConfiguration=Builder.<String>create()
    .withSideA(()-> serviceOld.call())
    .withSideB(()-> serviceNew.call())
    .withResultValidator(mustEqual)
    .withRoutingCriterion(countingCriterion)
    .withRoutingMode(RoutingMode.A_SIDE)
    .build();
    
    EndpointRouter<String> router = new EndpointRouter<>(routingConfiguration);
    String result=router.route();
```

The **RoutingConfiguration** takes two commands which implement the integration logic with the A and B endpoints. The **RoutingConfiguration** instance requires a validator which is used to validate the response objects from A and B endpoints, whereas a routing criterion to decide when the B side needs to 
be called. The **Routing Mode** defines the operating mode of the EndpointRouter. A_SIDE is used to route all requests to the A endpoint (the existing integration) and B_SIDE works like A_SIDE, but this time all requests will be routed to the B endpoint (the new integration). **SHADOW_MODE_PASSIVE** results in calling both endpoints simultaneously. If the A-B validation succeeds, in other words A and B endpoint's results are compatible, the **EndpointRouter** returns the result object from the A side, **SHADOW_MODE_ACTIVE**, in case the A-B validation succeeds, it returns the result object from the B side.

Darkest is a simple framework to validate two execution paths, they are implemented as commands. It will route the incoming requests depending on the routing criterion and assesses the outcome from the execution of both command. You can enhance the library by implementing new Monitorables, e.g., whenever the new endpoint gets called or the endpoint responses diverge, you can register new metrics at your monitoring endpoint and make the roll-out visible. If you have new ideas, feel free to join the project: 
[https://github.com/reevik/darkest](https://github.com/reevik/darkest)